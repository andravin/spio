import argparse

import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

from spio.kernels import (
    Conv2dGw8Params,
    Conv2dGw8Config,
    Conv2dGw8WgradConfig,
    get_performance_model_file_name,
    PERFORMANCE_MODEL_EXTENSION,
)
from spio.util import import_dataclass_column

PARAMS_CLASSES = dict(Conv2dGw8Params=Conv2dGw8Params)
CONFIG_CLASSES = dict(
    Conv2dGw8Config=Conv2dGw8Config, Conv2dGw8WgradConfig=Conv2dGw8WgradConfig
)

# Suppress SettingWithCopyWarning
pd.options.mode.chained_assignment = None


def main():
    parser = argparse.ArgumentParser(
        description="Train a performance model for a given kernel."
    )
    parser.add_argument("--datafile", required=True, type=str, default=None, help="Path to SSV file generated by spio/benchmark.py")
    parser.add_argument("--device", required=True, type=str, default=None, help="The name of the device to build the model for")
    parser.add_argument("--arch", required=True, type=str, default=None, help="The compute capability of the device")
    parser.add_argument("--kernel", required=True, type=str, default=None, help="The name of the kernel to build the model for")
    parser.add_argument("--outputfile", type=str, default=None, help="Optional file to save the model to. Otherwise the filename is generated automatically.")
    args = parser.parse_args()

    df = pd.read_csv(args.datafile, delimiter=";")

    # Filter the data for the specified device, architecture, and kernel.
    df = df[
        (df["Device"] == args.device)
        & (df["Arch"] == args.arch)
        & (df["Kernel"] == args.kernel)
    ]

    print(f"Training model for {args.kernel} on {args.device} ({args.arch})")
    print(f"Number of samples: {len(df)}")

    # Drop unused features
    df.drop(
        columns=[
            "Kernel",
            "Kernel_Kwargs",
            "Device",
            "Arch",
            "TFLOP/s",
            "Eff BW[GB/s]",
            "Idx",
        ],
        inplace=True,
    )

    # Separate the features and target.
    X = df[["Params", "Config"]]
    y = df["Time[ms]"]

    X = import_dataclass_column(X, "Params", PARAMS_CLASSES)
    X = import_dataclass_column(X, "Config", CONFIG_CLASSES)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # Convert data to DMatrix format (optimized for XGBoost)
    dtrain = xgb.DMatrix(X_train, label=y_train)
    dtest = xgb.DMatrix(X_test, label=y_test)

    # Set XGBoost parameters
    params = {
        "objective": "reg:squarederror",  # Regression task
        "max_depth": 6,  # Maximum depth of the trees
        "eta": 0.1,  # Learning rate
        "subsample": 0.8,  # Fraction of data to be used for each tree
        "colsample_bytree": 0.8,  # Fraction of features to be used for each tree
        "seed": 42,  # For reproducibility
    }

    # Train the model
    num_rounds = 100  # Number of boosting rounds
    bst = xgb.train(params, dtrain, num_rounds)

    # Evaluate the model on the test set
    y_pred = bst.predict(dtest)
    mse = mean_squared_error(y_test, y_pred)
    print(f"Mean Squared Error: {mse:.3f} milliseconds")

    if args.outputfile is None:
        args.outputfile = get_performance_model_file_name(
            args.kernel, args.device, args.arch
        )

    if "." not in args.outputfile:
        args.outputfile += PERFORMANCE_MODEL_EXTENSION

    print(f"Saving model to {args.outputfile}")

    bst.save_model(args.outputfile)


if __name__ == "__main__":
    main()
